# -*- coding: utf-8 -*-
"""Hugging Face Langchain RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h2Yc9b-a5mxF17ALlu18X_EdbiFeIvzp
"""

!pip install -U langchain-community langchain-text-splitters

pip install transformers sentence-transformers faiss-cpu pypdf

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.llms import HuggingFacePipeline
from langchain_core.prompts import PromptTemplate

from langchain_core.output_parsers import StrOutputParser

from transformers import pipeline
from operator import itemgetter

"""Load PDF"""

loader = PyPDFLoader('Sample.pdf')
documents = loader.load()

print('Pages loaded:', len(documents))

"""Split Text into chunks"""

splitter = RecursiveCharacterTextSplitter(
    chunk_size = 500,
    chunk_overlap = 100
)

docs = splitter.split_documents(documents)
print('Chunks created:', len(docs))

"""Create Hugging Face Embeddings"""

embeddings = HuggingFaceEmbeddings(
    model_name = 'sentence-transformers/all-MiniLM-L6-v2'
)

"""Vector Store (FAISS) + Retriever"""

vectorstore = FAISS.from_documents(docs, embeddings)
retriever = vectorstore.as_retriever(search_kwargs={'k':3})

"""Hugging Face LLM"""

hf_pipeline = pipeline(
    'text2text-generation',
    model = 'google/flan-t5-base',
    max_new_tokens = 512
)

llm = HuggingFacePipeline(pipeline=hf_pipeline)

"""Prompt Template"""

prompt = PromptTemplate.from_template("""
Answer the question using ONLY the context below.
If the answer is not present, say 'I don't know'.

context:
{context}

Question:
{question}
""")

"""Built RAG Chain (CORE)"""

parser = StrOutputParser()


rag_chain = (
    {
        "context" : itemgetter('question') | retriever,
        "question" : itemgetter('question')
    }
    | prompt
    | llm
    | parser
)

"""Ask Questions"""

response = rag_chain.invoke({
    "question": "What is the goal of the AgriPredict system?"
})

print(response)

